【环球网科技报道 记者 李文瑶】近日，关于番茄小说平台增设“AI训练补充协议”的讨论仍在持续，甚至引发了平台作者的集体抵制。
其中一个重要的争议方向是：由AI大模型训练生成的网文作品版权，究竟属于谁？
对此，北京大学法学院教授、北京大学人工智能研究院AI安全与治理中心主任张平教授在中国人工智能产业发展联盟（以下简称“AIIA”）安全治理委员会成果发布会上对环球网科技记者表示，由人工智能技术发展所带来的版权问题、专利问题，已经处于非常紧迫
地
需要解决的状态。
“人工智能归根到底不是一个技术问题。”生成式人工智能引领了新一轮人工智能产业的发展，但在带来机遇的同时也引发了安全伦理问题，在张平等行业专家看来，人工智能不仅仅是技术问题，它还涉及伦理、法律、社会、文化等多个层面，这也是行业、国家等多个层面共同推动人工智能治理的重要原因。
人工智能：从技术问题到伦理安全问题
数据语料是训练AI必不可少的重要“原料”。
根据此次番茄小说发出的“AI训练补充协议”显示，“甲方（番茄小说）可将签约作品的全部或部分内容及相关信息（如作品名称、简介、大纲、章节、人物、作者个人信息、封面图等）作为数据、语料、文本、素材等用于标注、合成数据/数据库建设、AI人工智能研发、机器学习、模型训练、深度合成、算法研发等目前已知或未来开发的新技术研发/应用领域。”
这也意味着，网文作者在签署该协议后，平台可以将作者的网文语料、相关作品信息、作者信息用作大模型训练使用。同时平台强调：“签署后，训练生产内容受平台版权保护，不允许抄袭或盗版行为。”
这也引发了网文作者的不满。首先是目前训练后生产的内容，带有极强的作者个人写作特色，如果不做特殊标明，几乎无法判断是作者本人撰写还是机器生成。
这与近期一直在讨论的“AI换脸拟声”的情况类似。今年4月，北京互联网法院对全国首例AI生成声音人格权侵权案做出宣判，一审判决，被告方使用原告声音、开发案涉AI文本转语音产品未获得合法授权，构成侵权，书面赔礼道歉，并赔偿原告各项损失25万元。
在海外，演员与AI企业之间的诉讼也在引发关注。今年5月，漫威超英“黑寡妇”的扮演者斯嘉丽·约翰逊将OpenAI告上法庭，控诉ChatGPT非法使用自己的声音，要求下架AI合成语音。
AIIA安全治理委员会办公室主任石霖对记者说道：“现在随着AIGC内容越来越多，我们需要在一定程度上去区分到底哪些是人工生成，哪些是人工智能生成的。”
另一方面，对于抄袭或者盗版行为的判定，也引发了作者的担心。有作者反馈，自己撰写的小说大纲、网文等信息被“投喂”给AI大模型进行训练后，平台反而判断自己的原创内容属于抄袭，而机器生产的内容属于原创。
这也引发了行业对于AI内容安全治理的担忧。对此，中国人工智能秘书长、中国信息通信研究院余晓晖院长对记者表示，人工智能本身的技术创新，应用和发展有非常大的不确定性，如何释放出人工智能最大向善的能力，造福于人类，促进我们经济社会发展，需要世界各国一起共同进一步推动。
“开展人工智能安全治理工作不仅是我们国家推动人工智能发展和安全的一个非常重要的工作，其实也是全球和我们人类共同需要对待的重大问题。”
人工智能治理成为新挑战
如何更好地进行人工智能安全治理工作？石霖说道，AIIA安全治理委员会是希望能够建立统一内容标识的平台，去实现内容可溯源、可追溯的能力，从而提升整理的人工智能治理能力。
目前，我国已颁布实施《互联网信息服务深度合成管理规定》《生成式人工智能服务管理暂行办法》等相关法律，但在针对AI领域的司法治理仍有进一步细化空间。
AIIA安全治理委员会主任委员、公安部信息安全等级保护评估中心原副主任、研究员毕马宁表示，过去一年，大模型发展速度之快，赋能范围之广，让我们看到通用人工智能的实现路径与曙光，但人工智能安全问题的严重性与紧迫性不容忽视。当我们从不同层面审视人工智能安全问题时，可以发现人工智能所带来的安全挑战已经从技术本身所带来的数据、算力、系统等传统安全问题，逐渐向对个人、组织、国家社会、人类生态的衍生安全问题蔓延。
在余晓晖看来，开展人工智能安全治理工作，可以从以下几个方面来进行思考：一是完善人工智能安全风险识别方法论。目前，人工智能技术日益融入经济社会发展各领域全过程，其安全风险面不断扩大，需要建立更加敏捷、精准的安全风险识别机制。
二是通过强化风险评估与防范，重点从人工智能基础设施、算法模型、上层应用以及产业链等方面进行评估，尽快尽早发现风险。
三是加强人工智能安全技术治理，加强对算法模型毒性、鲁棒性、公平性等方面的评测技术工具研究，通过技术治理技术。
四是需要加强国际合作，中国需要和全球一起共同研究推动全球性人工智能，我们达成更广泛的共识，共同释放我们人工智能潜力，也防范治理风险。
目前，中国信通院已经开展了大模型安全基准测试（AI Safety Benchmark）工作，联合产业界、学术界30余家单位对国内外开源、商用大模型开展安全测试，帮助产业界了解大模型的安全水位；同时发布了大模型安全加固解决方案，给出提升安全能力的实际措施。
人工智能安全已经成为全球议题
在AI治理规范方面，全球多个大国都已开始行动。去年11月，英国举办了首届全球人工智能安全峰会，美国、英国、欧盟、中国、印度等多方代表参加。今年5月，欧盟议会批准欧盟《人工智能法案》，这是世界上首部对人工智能进行全面监管的法案。
毕马宁介绍，目前，新加坡在原先治理框架基础上推出了《生成式人工智能治理模型框架》，提出人工智能评估需考虑的九个维度。日本发布《人工智能运营商指南》，为开发者、提供者、使用者制定行为准则。我国从《互联网信息服务算法推荐管理规定》到《生成式人工智能服务管理暂行办法》，对人工智能技术进行了精准化治理提供相关依据。
AI治理正在展现框架化、协同化趋势，我国也正积极拓展国际合作，7月1日，第78届联合国大会以协商一致方式通过了中国主提的“加强人工智能能力建设国际合作”决议，140多个国家参加联署。在7月2日外交部例行记者会上，外交部发言人毛宁表示，这充分反映了各国在加强人工智能能力建设方面的广泛共识，彰显了各国通过团结合作加强能力建设、弥合智能鸿沟的意愿。
在张平看来，在人工智能治理上，可以从三个维度来进行拆解：从最宏观层面，在联合国这个层面上倡导解决全人类共同面对的AI安全，所以我们就要强调以人为本，以人类利益为本。中观层面，从国家出发，关注国家安全、网络安全、基础设施安全；微观层面上就是进一步推动个人信息安全。
据了解，AIIA安全治理委员会已经启动推出“人工智能安全守护计划”，打造AI Guard品牌。中国信息通信研究院与国际组织开展了双边和多边的讨论交流，共同推动人工智能在全球的发展和安全治理。
面对人工智能带来的不确定性、安全风险和挑战，国际社会需要共同合作，共同推动人工智能安全治理。
中国科学院自动化研究所研究员、国家新一代人工智能治理专委会委员、联合国人工智能高层顾问机构专家曾毅表示，人工智能安全与能力不是相互掣肘的关系，更安全的系统实际上具有更强的认知能力，同时，人工智能安全工作也不应仅仅是修复问题，而应是建构性的，从被动反应转为主动设计。“人工智能的发展和安全已经成为全球性的议题，需要国际社会共同努力。”他说道。