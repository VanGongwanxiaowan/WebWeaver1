Agentic finetuning. While 30B-scale LLMs (e.g., Qwen3-30b-a3b-Instruct-2507) possess strong foundational capabilities, they often exhibit deficiencies in stability and instruction-following when executing complex, multi-turn tool-calling sequences over long contexts. To bridge this critical gap, we constructed a high-quality Supervised Fine-Tuning (SFT) dataset: WebWeaver-3k. The process began by sourcing a diverse set of queries crawled from the web, which were then processed by a powerful, tier teacher model, instantiated within our WebWeaver agent framework. A stringent filtering protocol was applied to the resulting end-to-end research trajectories, retaining only those where the agent successfully executed the entire workflow and strictly adhered to the predefined action format. This quality control yielded a curated dataset of 3.3k high-fidelity planning trajectories and 3.1k writing trajectories. As detailed in Table 4 and Fig. 14, these trajectories encapsulate the profound complexity of the OEDR task, with an average case involving approximately 15 search steps, over two outline optimizations, and the processing of over 62,000 evidence tokens. We performed full-parameter supervised fine-tuning on Qwen3-30b-a3b-Instruct with WebWeaver-3k. The model was trained for 1000 iterations on 16 NVIDIA H20 GPUs using a learning rate of 
7
×
10
−
6
. By fine-tuning our base model on this data, we explicitly imbued it with the requisite long-sequence reasoning and tool-use capabilities to master our framework.


智能体微调。虽然300亿参数规模的大语言模型（例如Qwen3-30b-a3b-Instruct-2507）具备强大的基础能力，但在长语境下执行复杂、多轮工具调用序列时，它们往往在稳定性和指令遵循方面存在不足。为了弥补这一关键差距，我们构建了一个高质量的有监督微调（SFT）数据集：WebWeaver-3k。该过程首先从网络上爬取各种不同的查询，然后由一个强大的层级教师模型在我们的WebWeaver智能体框架内进行处理。我们对生成的端到端研究轨迹采用了严格的过滤协议，只保留那些智能体成功执行整个工作流程并严格遵循预定义动作格式的轨迹。这种质量控制产生了一个精心筛选的数据集，包含3300条高保真规划轨迹和3100条写作轨迹。如表格4和图14所示，这些轨迹涵盖了OEDR任务的高度复杂性，平均每个案例涉及约15个搜索步骤、两次以上的大纲优化，以及超过62,000个证据标记的处理。我们使用WebWeaver-3k对Qwen3-30b-a3b-Instruct进行了全参数有监督微调。该模型在16块NVIDIA H20 GPU上训练了1000次迭代，学习率为7×10⁻⁶。通过在这些数据上微调我们的基础模型，我们明确地赋予了它掌握我们框架所需的长序列推理和工具使用能力。


The efficacy of our SFT strategy is quantitatively demonstrated by the significant performance gains across all benchmarks on Fig. 14, which directly reflect the model’s acquisition of our framework’s core competencies. The most dramatic validation is the leap in citation accuracy from a nearly unusable 25% to a reliable 85.90%. This provides direct, empirical evidence that the model has mastered the intricate mechanics of our Writer agent, learning to execute precise tool calls for evidence retrieval and faithfully write according to the source-grounded outline. Furthermore, the substantial increase in overall report quality, evidenced by the score on DeepConsult (4.57 → 6.09) and the massive jump on DeepResearchGym (77.27 → 90.89), reflects the successful acquisition of the planner’s more abstract abilities. These holistic improvements indicate that the model has learned the core loop of thinking (iteratively optimizing the outline) and searching (adaptively acquiring evidence), which is a prerequisite for generating a comprehensive and insightful final report. Ultimately, these results offer a powerful dual validation: they prove that our WebWeaver framework is a potent data generation engine, capable of deconstructing the formidable OEDR task into learnable demonstrations of thinking, searching, and writing, thereby enabling a smaller model to achieve expert-level performance.

我们的监督微调（SFT）策略的有效性通过图14中所有基准测试的显著性能提升得到了定量证明，这直接反映了模型对我们框架核心能力的掌握。最显著的验证是引用准确率从几乎无法使用的25%跃升至可靠的85.90%。这提供了直接的实证证据，表明该模型已经掌握了我们Writer智能体的复杂机制，学会了执行精确的工具调用以检索证据，并能根据基于来源的大纲如实撰写内容。此外，整体报告质量的大幅提升（从DeepConsult的4.57分提升至6.09分，从DeepResearchGym的77.27分大幅跃升至90.89分）反映了规划器更抽象能力的成功习得。这些全面的改进表明，该模型已经掌握了思考（迭代优化大纲）和搜索（自适应获取证据）的核心循环，这是生成全面且有洞察力的最终报告的前提。最终，这些结果提供了强有力的双重验证：它们证明我们的WebWeaver框架是一个高效的数据生成引擎，能够将艰巨的OEDR任务分解为可学习的思考、搜索和写作示范，从而使较小的模型能够达到专家级性能。

# 5Related Works 5 相关工作


Open-Ended Deep Research. Deep Research Agents have garnered significant attention for their powerful capabilities in information seeking, integration, and reasoning. Proprietary systems, such as DeepResearch (OpenAI, 2025a), Gemini Deep Research (google, 2025), and Claude Research (anthropic, 2025), have demonstrated performance comparable to human experts in domains like fact-checking and report writing. However, their opaque internal architectures and workflows hinder broader research and development. In the open-source community, many studies (Li et al., 2025b; Tao et al., 2025; Su et al., 2025; Qiao et al., 2025; Fang et al., 2025; Li et al., 2025a; Wu et al., 2025b; a; Li et al., 2024b) have been developed to tackle complex research Question-Answering (QA) benchmarks. Nevertheless, these solutions are primarily tailored for short-answer research queries and lack the capability to generate comprehensive, long-form reports on open-domain topics. Other open-source systems like OpenDeepResearch (Research, 2025e), GPT Researcher (Research, 2025c), and TTD-DR (Han et al., 2025) address long-form generation by first drafting a static framework, then retrieving content, and finally composing the report. This approach, characterized by a fixed structure and one-step generation, often leads to textual incoherence and hallucinations. While recent works like WriteHere (Xiong et al., 2025), STORM (Shao et al., 2024), and SCISAGE (Shi et al., 2025) utilize searched content to generate or refine the outline, the search-first method also constrains the searching boundary without outline guidance. In sharp contrast, WebWeaver enables a truly synergistic research cycle where the outline and search strategy co-evolve, allowing emergent findings to continuously reshape the research direction in real time.


开放式深度研究。深度研究智能体凭借其强大的信息获取、整合和推理能力获得了广泛关注。专有系统，如DeepResearch（OpenAI，2025a）、Gemini深度研究（谷歌，2025）和Claude研究（Anthropic，2025），在事实核查和报告撰写等领域展现出了与人类专家相当的性能。然而，它们不透明的内部架构和工作流程阻碍了更广泛的研究与开发。在开源社区，已有多项研究（Li等人，2025b；Tao等人，2025；Su等人，2025；Qiao等人，2025；Fang等人，2025；Li等人，2025a；Wu等人，2025b；a；Li等人，2024b）致力于解决复杂的研究型问答（QA）基准问题。尽管如此，这些解决方案主要是为短答案研究查询量身定制的，缺乏针对开放域主题生成全面、长篇报告的能力。其他开源系统，如OpenDeepResearch（Research，2025e）、GPT Researcher（Research，2025c）和TTD-DR（Han等人，2025），通过先起草一个静态框架，然后检索内容，最后撰写报告的方式来解决长篇生成问题。这种以固定结构和一步生成为特点的方法，往往会导致文本不连贯和幻觉现象。虽然近期的研究成果如WriteHere（Xiong等人，2025）、STORM（Shao等人，2024）和SCISAGE（Shi等人，2025）利用搜索到的内容来生成或完善大纲，但这种先搜索的方法在没有大纲指导的情况下也会限制搜索范围。与之形成鲜明对比的是，WebWeaver实现了真正协同的研究周期，其中大纲和搜索策略共同进化，使新发现能够实时不断地重塑研究方向。

Long Writing. Ensuring the coherence and accuracy of LLM-generated long-form text is a persistent challenge. Previous work has explored methods like recursive prompting for story extension (Yang et al., 2022) and structured task decomposition to improve consistency (Yang et al., 2023; Wang et al., 2025; Huot et al., 2025). More recently, agent-based frameworks have become a mainstream solution. Systems like LongWriter (Bai et al., 2025), and CogWriter (Wan et al., 2025) employ a "plan-then-write" strategy, where a planner first creates an outline, and a writer then conditions on this plan to produce the full text. However, these methods rely on a static initial plan and a brute-force writing strategy by feeding all the evidence into LLMs. In contrast, our approach uniquely enables the outline to be dynamically optimized in tandem with the evidence acquisition process, allowing for a comprehensive, source-grounded research outline. While recent works (Huot et al., 2025; Shao et al., 2024) adopted the multi-agent paradigm to write sections in parallel, with evidence retrieval based on the section title, the separate writing often leads to content and style incoherence, and the retrieval using titles also brings noisy evidence. In contrast, our agentic hierarchical writing model is designed to foster both global coherence and local depth. Its sequential, single-agent process allows cross-sectional thinking by maintaining a continuous narrative flow between sections. At the same time, its reliance on precise, citation-grounded evidence enables deep internal reasoning within each section. This combination allows the writer to produce a cohesive, accurate, and insightful report.

长文本写作。确保大语言模型生成的长篇文本的连贯性和准确性是一项长期存在的挑战。以往的研究探索了多种方法，例如用于故事扩展的递归提示（Yang等人，2022）以及用于提高一致性的结构化任务分解（Yang等人，2023；Wang等人，2025；Huot等人，2025）。最近，基于智能体的框架已成为主流解决方案。像LongWriter（Bai等人，2025）和CogWriter（Wan等人，2025）这类系统采用“先规划后写作”的策略，即先由规划器制定大纲，然后由写作者根据该大纲生成完整文本。然而，这些方法依赖于静态的初始计划，并且通过将所有证据输入大语言模型来采用蛮力写作策略。相比之下，我们的方法独特之处在于，能够随着证据获取过程动态优化大纲，从而形成一个全面的、基于来源的研究大纲。尽管最近的研究（Huot等人，2025；Shao等人，2024）采用多智能体模式并行撰写各个部分，并基于 section 标题进行证据检索，但这种分开写作的方式往往会导致内容和风格不一致，而且使用标题进行检索也会带来有噪声的证据。相反，我们的智能体分层写作模型旨在同时实现全局连贯性和局部深度。其顺序式的单智能体流程通过在各部分之间保持连续的叙事流，实现了跨 section 思考。同时，它依赖精确的、基于引用的证据，从而在每个 section 内部实现深入的推理。这种结合使写作者能够生成连贯、准确且富有洞察力的报告。

# 6Conclusion 6 结论

In this paper, we introduced WebWeaver, a novel dual-agent framework designed to overcome the fundamental flaws of static, machine-like pipelines in open-ended deep research (OEDR). By emulating the human cognitive process that integrates the planner’s dynamic research cycle with the writer’s hierarchical retrieval and writing process, WebWeaver consistently outperforms both proprietary and open-source systems, establishing a new state-of-the-art.
在本文中，我们介绍了WebWeaver，这是一个新颖的双智能体框架，旨在克服开放式深度研究（OEDR）中静态、机器式流程的根本缺陷。通过模拟人类认知过程——该过程将规划者的动态研究周期与写作者的分层检索和写作过程相结合，WebWeaver持续优于专有系统和开源系统，树立了新的技术标杆。

Beyond its superior performance, the true significance of WebWeaver lies in the new paradigm it offers the community for tackling complex, information-intensive tasks. It reframes the intractable challenge of long-context reasoning, demonstrating that it can be successfully deconstructed into a structured problem of system-level information management, orchestrated through a series of precise actions. Both the planner and writer are embodiments of this principle: they use tools to dynamically explore, structure, and write, rather than passively processing it in a single pass. This work does not just present a better agent system; it presents a new blueprint for building the agent system that masters intensive knowledge through deliberate actions, not just brute-force attention.
除了卓越的性能外，WebWeaver的真正意义在于它为社区提供了一种应对复杂、信息密集型任务的新范式。它重新定义了长上下文推理这一棘手挑战，表明该挑战可以成功分解为系统级信息管理的结构化问题，并通过一系列精确的操作来协调。规划器和写入器都是这一原则的体现：它们使用工具来动态探索、构建结构和进行写入，而不是一次性被动处理信息。这项工作不仅展示了一个更出色的智能体系统，还提供了一个构建智能体系统的新蓝图——通过有意识的行动而非单纯的暴力注意力来掌握密集知识。

